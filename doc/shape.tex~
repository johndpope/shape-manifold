\documentclass[anon,10pt]{9520} % Anonymized submission
% \documentclass{colt2012} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

\newcommand{\mb}{\mathbf}

\usepackage{comment}
\usepackage{multirow,graphicx}

\title[Semi-Supervised Shape Classification]{Semi-Supervised Shape Classification with Manifold Regularization}

 % Use \Name{Author Name} to specify the name.  If the surname contains spaces,
 % enclose the surname in braces, e.g. \Name{John {Smith Jones}} similarly if
 % the name has a "von" part, e.g \Name{Jane {de Winter}}.  If the first letter
 % in the forenames is a diacritic enclose the diacritic in braces,
 % e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address \coltauthor{\Name{Author Name1}
  % \Email{abc@sample.com}\and \Name{Author Name2}
  % \Email{xyz@sample.com}\\ \addr Address}

 % Three or more authors with the same address: \coltauthor{\Name{Author Name1}
 % \Email{an1@sample.com}\\ \Name{Author Name2}
 % \Email{an2@sample.com}\\ \Name{Author Name3} \Email{an3@sample.com}\\ \addr
 % Address}


 % Authors with different addresses: 

\author{\Name{Stanislav Nikolov}
\Email{snikolov@mit.edu}\\}

\begin{document}

\maketitle

%TODO: 

% [x] Compare best-performing for image and best-performing for SDF (for poor
% conditions and good conditions)

% Compare best performing of the above to best performing kNN. 

% Talk about effect of sigma. Why does it not matter much?

% Talk about why we use a single sigma for the kernel.

% Talk about actual implementation details of algorithm / experiment. How
% many/what kind of parameter tuning, cross-validation, train test splits, etc.

% PLOTS

% * Better explain the PCA thumbnail plot.

% * Examples of classification (in PCA space).


\begin{abstract}
We approach the problem of semi-supervised shape classification by exploiting
the geometric structure of shape data. We apply {\em manifold regularization} to
learn a function from shapes to class labels. Central to manifold regularization
algorithms is the use of a weighted graph to represent pairwise relationships
between training points and capture their geometric structure. Under a
regularized least squares formulation, each algorithm only involves solving a
linear system of equations.

We analyze the classification performance for different features, length scales
of the graph weights, and levels of class imbalance. We show that encouraging
the smoothness of the classification function on the manifold improves
classification performance. We observe, somewhat surprisingly, that
classification performance is not very sensitive to the length scale of the
graph weights for suitable kernels. We compare raw pixel features to Signed
Distance Function (SDF) features and find that SDF features are consistently
better.

In addition, we demonstrate that for imbalanced datasets, subsampling the
dominant class improves classification performance. Finally, we compare graph
regularization and manifold regularization to the much simpler inductive and
transductive versions of k-Nearest-Neighbors.  (and how did they compare?)
\end{abstract}

\begin{keywords}
shape classification, manifold regularization, semi-supervised learning.
\end{keywords}

\section{Introduction}

% Shape classification is important
In many object recognition and classification tasks, the shape of an object is
more important than its other qualities, such as color or texture. For example,
consider the task of classifying images of bottles and cups. The bottles and
cups themselves might have a variety of colors and textures, in addition to
noise and variation in background and lighting. In comparison, the silhouettes
of cups and bottles have fewer, albeit more important degrees of freedom. Shape
classification aims to exploit this.

Shape classification has many applications. Crowdsourced image annotation tools
such as LabelMe \cite{LabelMe} have generated hundreds of thousands of labeled
shapes from segmentions of everyday scenes, making it as feasible as ever to
learn models for everyday shapes and exploit them to do object recognition in
complex scenes. In the field of biomedical imaging, better classification on
shapes segmented from biomedical imaging data could help with early detection
and diagnosis of disease.

% Manifold
Recently, geometric frameworks for learning such as manifold learning and
manifold regularization \cite{people} have become a popular approach to image
and shape classification \cite{people}. While the raw pixels of an image form a
feature vector in a high-dimensional space, images are assumed to lie close to a
low-dimensional submanifold embedded in the high-dimensional ambient
space. Roughly, the low dimension of the manifold corresponds to a low number of
latent degrees of freedom in the set of images.

% As a proxy for geometry-exploiting algorithms
% TODO: weak
We chose to study shape classification as a proxy for studying the behavior of
geometry-aware learning algorithms on more complex datasets, such as real-world
images. Although real-world images have many more degrees of freedom than
silhouettes, both have relatively few latent degrees of freedom and can be
assumed to lie on a low dimensional submanifold embedded in the ambient space.


\section{The Manifold Setting}
\subsection{The Manifold Assumption}

% Talk about points being generated from a manifold, etc.

% Plot of points with images overlaid.

\begin{figure}
\begin{center}
\includegraphics[width=5in]{fig/img_overlay}
\end{center}
\end{figure}

\subsection{Semi-supervised Learning and Manifold Regularization}
In a semi-supervised learning setting, there is a set of $n$ points $\{\mb
x_i\}_{i=1,\dots,n}$, of which the first $\ell$ have labels
$\{y_i\}_{i=1,\dots,\ell}$ and the remaining $u=n-\ell$ are unlabeled. The goal
is to learn a function $f$ that predicts the label of an arbitrary (potentially
unobserved) point. In a fully-supervised learning setting, one would use only
the labeled points to learn $f$. Regularized Least Squares (RLS), for example,
attempts to learn $f$ by minimizing the regularized squared
loss \[\frac{1}{\ell}\sum_{i=1}^{\ell} (f(\mb{x}_i)-y_i)^2 + \lambda_A
\|f\|_{\mathcal{H}}^2\] which can be written as \[ \frac{1}{\ell}\|\mb{K}\mb{c}
- \mb{y}\|_2^2 + \lambda_A \mb{c}^T \mb{K} \mb{c} \] using the kernel matrix
$\mb{K}$ and coefficients $\mb{c}$ given by the Representer Theorem.

Manifold learning uses the unlabeled points in addition to the labeled points in
order to exploit the geometry of the data. \cite{Belkin} Namely, it exploits the
idea that $f$ should not vary drastically in regions of high density. This idea
is captured formally by defining an intrinsic smoothness penalty on
$f$ \[\|f\|^2_{I} = \int_{\mathcal{M}} \|\nabla_{\mathcal{M}} f(x)\|^2 dp(\mb x)
= \int\Delta_{\mathcal{M}}f dp(\mb x), \] where $\nabla_{\mathcal{M}}$ and
$\Delta_{\mathcal{M}}$ are the gradient and Laplacian of $f$ on the manifold,
respectively. This gives rise to Laplacian Regularized Least Squares (LapRLS)
where one minimizes \[ \frac{1}{\ell} \sum_{i=1}^{\ell} (f(\mb{x}_i)-y_i)^2 +
\lambda_A \|f\|_{\mathcal{H}}^2 + \lambda_I\|f\|_I.\] Furthermore, one can
approximate the intrinsic smoothness penalty using only the observed points by
using a graph Laplacian instead of the manifold Laplacian: $\mb x_1, \dots, \mb
x_n$: \[\|f\|^2_I \approx \frac{1}{2n^2} \sum_{i=1}^{n} \sum_{j=1}^{n}
W_{i,j}(f_i-f_j)^2 = \mb f^T \mb L \mb f.\] Here \[W_{i,j} =
e^{-\frac{\|\mb{x}_i-\mb{x}_j\|^2}{2\sigma^2}}\] are similarity weights for some
scale parameter $\sigma$ and $\mb L$ is the graph Laplacian of the graph defined
by the $W_{i,j}$s. Manifold regularization has its own representer theorem,
which allows us to write the objective as
\[ \frac{1}{\ell} \|\mb J(\mb K \mb c-\mb y')\|^2 + \lambda_A \mb c^T \mb K \mb c + \frac{1}{n^2} \mb c^T \mb K \mb L \mb K \mb c \]

\begin{comment}
\subsection{Class Imbalance}
Often, datasets do not have an equal number of positive and negative
examples. This situation, known as {\em class imbalance} makes the dominant
class more likely to be predicted, as examples from the dominant examples stand
to accumulate greater loss because of their greater number. This is typically
resolved by assigning a weight $\gamma_i$ to each point $\mb x_i$, which in our
case leads to a weighted LapRLS objective
\[ \frac{1}{\ell} \|\mb J \mb \Gamma(\mb K \mb c-\mb y')\|^2 + \lambda_A \mb c^T \mb K \mb c + \frac{1}{n^2} \mb c^T \mb K \mb L \mb K \mb c,\] where $\mb \Gamma$ is a diagonal matrix with weights $\gamma_1,\dots,\gamma_{\ell}$ as its first $\ell$ entries and zeros as its remaining $u$ entries. See \cite{Weiss} (G. Weiss. Mining with rarity: A unifying framework.SIGKDD Explorations, 6(1):7-19) and \cite{Kotsiantis} (Handling imbalanced datasets: A review Sotiris Kotsiantis, Dimitris Kanellopoulos, Panayiotis Pintelas)
2004.
\end{comment}

\section{Classification Task}

\subsection{Data}
To represent shapes, we used binary ``silhouette'' images from the Large Binary
Image Database \texttt{(http://www.lems.brown.edu/\textasciitilde{}dmc/)}. We randomly sampled a roughly
equal amount of images of butterflies (161), dogs (154), heads (149), and fish
(156).
\begin{figure}[h!]
\begin{center}
\includegraphics[width=5in]{fig/example_shapes}
\end{center}
\caption{\label{fig:image_examples} Dog and butterfly shapes as binary silhouette images.}
\end{figure}
The images are not all the same dimensions and are typically rectangular. Therefore,
via padding and cropping, we converted each image to be $s$ by $s$ pixels, where
$s$ is the larger of the maximum width and maximum height over all images.  As
an optional step, one can rescale each image so that that shapes are of
comparable size. We found most of the shapes to be of similar scale and
therefore omitted this step. Next, we created two feature representations from
each image, each of which is ``image-like'' and has the same dimensions as the
original image. The first feature representation is simply the raw pixels of the
image. The second feature representation is the discretized {\em signed distance
  function} \cite{people}, which we will describe shortly. Finally, to reduce
dimensionality, each feature representation is scaled down.

\subsubsection{Signed Distance Functions} 
A {\em signed distance function} (SDF) is an object that implicitly defines a
partition of a space into (possibly multiply-connected) inside and outside
regions. In our case, the space is a plane, and the boundary between the inside
and outside regions can be thought of as a shape. SDFs take in a point $\mb{x}$
(e.g. in the plane) and give the {\em signed distance} to the closest point on
the boundary. If $\mb{x}$ is in the inside region, the signed distance is
negative; if it is in the outside region, the signed distance is
positive. Hence, the boundary, or shape, is given by the zero contour of the SDF.
\begin{figure}[h!]
\begin{center}
\includegraphics[width=4in]{fig/bin_vs_sdf}
\end{center}
\caption{\label{fig:bin_vs_sdf} Signed Distance Functions are implicit representations of shapes.}
\end{figure}

% Data, etc.

\section{Results}

\subsection{Effect of Regularization}

\begin{table}[h!]
\tiny
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\multicolumn{5}{c}{$p_{flip} = 0.2$, $p_{labeled} = 0.05$}\\
\multicolumn{5}{c}{Image features}\\
\hline
Class 1 & Class 2 & Features & Mode & Accuracy\\\hline

butterflies&	fish&	image&	RLS&	0.58$\pm$0.07\\
butterflies&	fish&	image&	LapRLS& \textbf{0.82$\pm$0.04}\\\hline

butterflies&	heads&	image&  RLS& 0.80$\pm$0.22\\
butterflies&	heads&	image&	LapRLS& \textbf{0.81$\pm$0.23}\\\hline

butterflies&	dogs&	image&	RLS&	0.62$\pm$0.17\\
butterflies&	dogs&	image&	RLS&      \textbf{0.76$\pm$0.10}\\\hline

fish&	heads&	image&	RLS&	0.75$\pm$0.16\\
fish&	heads&	image&	LapRLS&	\textbf{0.95$\pm$0.03}\\\hline

fish&	dogs&	image&	RLS&	0.61$\pm$0.14\\
fish&	dogs&	image&	LapRLS&	\textbf{0.69$\pm$0.16}\\\hline

heads&	dogs&	image&	RLS&	0.58$\pm$0.14\\
heads&	dogs&	image&	LapRLS&	\textbf{0.75$\pm$0.12}\\\hline
\multicolumn{5}{c}{SDF features}\\\hline
butterflies&	fish&	SDF&    RLS&	0.77$\pm$0.03\\
butterflies&	fish&	SDF&	LapRLS&	\textbf{0.86$\pm$0.10}\\\hline

butterflies&	heads&	SDF&	RLS&	0.98$\pm$0.03\\
butterflies&	heads&	SDF&	LapRLS&	\textbf{0.99$\pm$0.00}\\\hline

butterflies&	dogs&	SDF&	RLS&	\textbf{0.91$\pm$0.04}\\
butterflies&	dogs&	SDF&	LapRLS&	0.91$\pm$0.06\\\hline

fish&	heads&	SDF&	RLS&	0.97$\pm$0.01\\
fish&	heads&	SDF&	LapRLS&	\textbf{0.98$\pm$0.01}\\\hline

fish&	dogs&	SDF&	RLS&	0.87$\pm$0.02\\
fish&	dogs&	SDF&	LapRLS&	\textbf{0.89$\pm$0.03}\\\hline

heads&	dogs&	SDF&	RLS&	0.73$\pm$0.22\\
heads&	dogs&	SDF&	LapRLS&	\textbf{0.93$\pm$0.03}\\\hline
\end{tabular}
\begin{tabular}{|c|c|c|c|c|}
\multicolumn{5}{c}{$p_{flip} = 0$, $p_{labeled} = 0.25$}\\
\multicolumn{5}{c}{Image features}\\
\hline
Class 1 & Class 2 & Features & Mode & Accuracy\\\hline

butterflies&	fish&	image&	RLS&	0.77$\pm$0.09\\
butterflies&	fish&	image&	LapRLS&	\textbf{0.90$\pm$0.02}\\\hline

butterflies&	heads&	image&		RLS&	\textbf{0.99$\pm$0.01}\\
butterflies&	heads&	image&		LapRLS&	0.99$\pm$0.02\\\hline

butterflies&	dogs&	image&		RLS&	0.87$\pm$0.10\\
butterflies&	dogs&	image&		LapRLS&	\textbf{0.95$\pm$0.01}\\\hline

fish&	heads&	image&		RLS&			0.95$\pm$0.05\\
fish&	heads&	image&		LapRLS&			\textbf{0.99$\pm$0.00}\\\hline

fish&	dogs&	image&		RLS&			0.83$\pm$0.02\\
fish&	dogs&	image&		LapRLS&			\textbf{0.90$\pm$0.10}\\\hline

heads&	dogs&	image&		RLS&			0.85$\pm$0.12\\
heads&	dogs&	image&		LapRLS&			\textbf{0.94$\pm$0.04}\\\hline
\multicolumn{5}{c}{SDF features}\\\hline
butterflies&	fish&	SDF&		RLS&			0.93$\pm$0.01\\
butterflies&	fish&	SDF&		LapRLS&			\textbf{0.94$\pm$0.02}\\\hline

butterflies&	heads&	SDF&		RLS&			\textbf{1.00$\pm$0.00}\\
butterflies&	heads&	SDF&		LapRLS&			\textbf{1.00$\pm$0.00}\\\hline

butterflies&	dogs&	SDF&		RLS&			0.98$\pm$0.01\\
butterflies&	dogs&	SDF&		LapRLS&			\textbf{0.98$\pm$0.00}\\\hline

fish&	heads&	SDF&		RLS&			0.98$\pm$0.01\\
fish&	heads&	SDF&		LapRLS&			\textbf{0.99$\pm$0.01}\\\hline

fish&	dogs&	SDF&		RLS&			0.96$\pm$0.01\\
fish&	dogs&	SDF&		LapRLS&			\textbf{0.97$\pm$0.01}\\\hline

heads&	dogs&	SDF&		RLS&			0.94$\pm$0.01\\
heads&	dogs&	SDF&		LapRLS&			\textbf{0.99$\pm$0.01}\\\hline
\end{tabular}
\end{center}
\caption{\label{tbl:rls_laprls} LapRLS outperforms RLS for both image and SDF
  features, as well as under both noisy and sparsely labeled conditions
  ($p_{flip} = 0.2$, $p_{labeled} = 0.05$) and noiseless and more densely
  labeled conditions ($p_{flip} = 0$, $p_{labeled} = 0.25$).}
\end{table}

\subsection{Comparison of Features}
\begin{table}[h!]
\tiny
\begin{center}
\begin{tabular}{|c|c|c|c|}
\multicolumn{4}{c}{$p_{flip} = 0.2$, $p_{labeled} = 0.05$}\\
\hline
Class 1 & Class 2 & Features & Accuracy\\\hline

butterflies&	fish&	image&	0.82$\pm$0.04\\
butterflies&	fish&	SDF&	\textbf{0.86$\pm$0.10}\\\hline

butterflies&	heads&	image&	0.81$\pm$0.23\\
butterflies&	heads&	SDF&	\textbf{0.99$\pm$0.00}\\\hline

butterflies&	dogs&	image&	0.76$\pm$0.10\\
butterflies&	dogs&	SDF&	\textbf{0.91$\pm$0.04}\\\hline

fish&	heads&	image&	0.95$\pm$0.03\\
fish&	heads&	SDF&	\textbf{0.98$\pm$0.01}\\\hline

fish&	dogs&	image&	0.69$\pm$0.16\\
fish&	dogs&	SDF&	\textbf{0.89$\pm$0.03}\\\hline

heads&	dogs&	image&	0.75$\pm$0.12\\
heads&	dogs&	SDF&	\textbf{0.93$\pm$0.03}\\\hline
\end{tabular}
\begin{tabular}{|c|c|c|c|}
\multicolumn{4}{c}{$p_{flip} = 0$, $p_{labeled} = 0.25$}\\
\hline
Class 1 & Class 2 & Features & Accuracy\\\hline

butterflies&	fish&	image&		0.90$\pm$0.02\\
butterflies&	fish&	SDF&					\textbf{0.94$\pm$0.02}\\\hline

butterflies&	heads&	image&	0.99$\pm$0.01\\
butterflies&	heads&	SDF&					\textbf{1.00$\pm$0.00}\\\hline

butterflies&	dogs&	image&			0.95$\pm$0.01\\
butterflies&	dogs&	SDF&					\textbf{0.98$\pm$0.00}\\\hline

fish&	heads&	image&					\textbf{0.99$\pm$0.00}\\
fish&	heads&	SDF&					0.99$\pm$0.01\\\hline

fish&	dogs&	image&					0.90$\pm$0.10\\
fish&	dogs&	SDF&					\textbf{0.97$\pm$0.01}\\\hline

heads&	dogs&	image&					0.94$\pm$0.04\\
heads&	dogs&	SDF&					\textbf{0.99$\pm$0.01}\\\hline

\end{tabular}

\end{center}
\caption{\label{tbl:features} The table above compares the best outcomes for
  image features and SDFs from Table \ref{tbl:rls_laprls} and shows that SDF
  features outperform image features.}
\end{table}

In both graph regularization and manifold regularization, there are parameters
to optimize. In graph regularization, we have a regularization parameter
$\lambda$ and a scale parameter $\sigma$.

\subsection{Comparison to kNN}

% Graph or Table?

\subsection{Experiments and Evaluation}

\section{Discussion}

\subsection{Advantage of Regularization}
It is well known that regularization helps avoid overfitting.

\subsection{Advantage of SDF Features}
With a sufficiently high percentage of labeled data and no noise
(!!!!!!!!!!!POINT TO RESULTS!!!!!!!!!!) SDFs features outperform image features
noticeably on the more difficult datasets. We believe this to be because SDFs
are smoother than raw images and better obey the manifold assumption. For
example, consider binary images of handwritten 2s. Two 2s might be very similar
in shape, yet have almost no overlap because they are so narrow in most
places. The SDFs of those shapes, however, will overlap significantly. Thus,
shapes that would be considered close are in fact close in the feature space,
leading to a more well-behaved manifold.

\subsection{Sensitivity to Graph Weight Scaling}
We observe that the classification performance of both RLS and LapRLS are a lot
less sensitive to sigma than Graph Regularization. We believe this is because
RLS and LapRLS both enforce the overall smoothness of $f$.

\subsection{Imbalanced Data}
%\bibliography{yourbibfile}

\end{document}
